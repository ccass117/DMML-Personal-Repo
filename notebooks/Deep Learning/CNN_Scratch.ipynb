{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install --upgrade torch\n",
    "%pip install --upgrade torchvision\n",
    "%pip install tensorflow\n",
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Dataset\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "data_dir = \"'..\\data\\separated_imgdata'\"\n",
    "\n",
    "dataset = PokemonDataset(data_dir, transform)\n",
    "image, label = dataset[100]\n",
    "image.shape\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes = len(dataset.classes)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (224-6) * (224-6), num_classes)\n",
    "        )\n",
    "    \n",
    "    # def classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "model = Model().to('cuda')\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,)\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimiser, step_size=2, gamma=0.1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    best_score = np.inf\n",
    "    patience = 5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            dataloader = trainloader if phase == 'train' else testloader\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(f'Learning Rate: {param_group[\"lr\"]}')\n",
    "\n",
    "            epoch_loss = running_loss / len(train_dataset if phase == 'train' else test_dataset)\n",
    "            epoch_acc = running_corrects.double() / len(train_dataset if phase == 'train' else test_dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "            \n",
    "        # Convergence Check\n",
    "        if(epoch_loss < best_score):\n",
    "            best_score = epoch_loss\n",
    "            print(f'Patience: {patience}')    \n",
    "        \n",
    "        else:\n",
    "            patience -= 1\n",
    "            print(f'Patience: {patience}')\n",
    "        \n",
    "        if patience <= 0:\n",
    "            print(f\"EARLY STOP at EPOCH #{epoch}\")\n",
    "            break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model, loss_func, optimiser, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "class_names = dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
